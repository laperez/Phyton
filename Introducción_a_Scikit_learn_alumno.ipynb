{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introducción a Scikit-learn - alumno.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laperez/Phyton/blob/master/Introducci%C3%B3n_a_Scikit_learn_alumno.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVn_IKGcpLsK",
        "colab_type": "text"
      },
      "source": [
        "# Introducción a Scikit-learn\n",
        "\n",
        "[Scikit-learn](https://scikit-learn.org/stable/) va a ser nuestra biblioteca principal para el procesamiento de datos, la generación de modelos (aprendizaje automático) y la evaluación de los mismos. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrUfDrd_pc4Q",
        "colab_type": "text"
      },
      "source": [
        "## Orígenes\n",
        "\n",
        "Esta herramienta comenzón en 2007 como un proyecto de David Cournapeau para el *Google Summer of Code* (una especie de seminario de verano). Ese mismo año se sumaría Matthieu Brucher, que tendría a este módulo de Python como tema central de su tesis. Posteriormente, en el año 2010, otros desarrolladores se subieron al barco de Scikit-learn, cuya navegación no ha parado desde entonces llevándonos a variados e interesantes puertos.\n",
        "\n",
        "Es una herramienta ya imprescindible en la comunidad del *Machine learning* y, al ser un proyecto de código abierto, tenemos toda la libertad para usarla en nuestras actividades de investigación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHSW5pT9phwl",
        "colab_type": "text"
      },
      "source": [
        "## Módulos principales\n",
        "\n",
        "Podemos distinguir seis bloques diferenciados de herramientas:\n",
        "\n",
        "1. Preprocesamiento\n",
        "1. Reducción de la dimensionalidad\n",
        "1. Clasificación\n",
        "1. Regresión\n",
        "1. Clustering\n",
        "1. Selección de modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJULAeu_pikS",
        "colab_type": "text"
      },
      "source": [
        "La mayoría de las clases que proporciona Scikit-learn implementando varios métodos clave:\n",
        "\n",
        "* **Constructor**, en el que se definen los hiperparámetros.\n",
        "* **fit()**: que sirve para ajustar (entrenar) el modelo y puede recibir más hiperparámetros\n",
        "* **transform()**: que aplica el modelo a los datos para transformarlos\n",
        "* **predict()**: que genera una predicción (clase o valor) para un conjunto de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFoAbNdjplwC",
        "colab_type": "text"
      },
      "source": [
        "En esta introducción vamos a ver un ejemplo de uso entrenando un modelo de clasificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyU8CBVSp99o",
        "colab_type": "text"
      },
      "source": [
        "# Clasificación\n",
        "\n",
        "El aprendizaje supervisado de un algoritmo de clasificación es idéntico al caso de la regresión:\n",
        "```\n",
        "modelo = AlgoritmoAprendizaje(hiperparámetros)\n",
        "modelo.fit(X_train, y_train)\n",
        "y_pred = modelo.predict(X_eval)\n",
        "evaluacion(y_pred, y_eval)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s07ZbfG9qBW2",
        "colab_type": "text"
      },
      "source": [
        "## Evaluación\n",
        "\n",
        "La diferencia está en cómo evaluamos e interpretamos esa evaluación. Las medidas más típicas son *Accuracy*, *Precision*, *Recall* y *F-score*.\n",
        "\n",
        "Recordemos la tabla de confusión para evaluar un clasificador:\n",
        "\n",
        "|  | pred_P | pred_N |\n",
        "| --- | --- | --- |\n",
        "| **ref_P** |  TP  | FN |\n",
        "| **ref_N** | FP | TN  |\n",
        "\n",
        "*Accuracy = (TP+TN) / (TP+FN+FP+TN)*\n",
        "\n",
        "*Precision = TP / (TP+FP)*\n",
        "\n",
        "*Recall = TP / (TP+FN)*\n",
        "\n",
        "*F-score = 2 * Precision * Recall / (Precision + Recall)*\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/800px-Precisionrecall.svg.png\" width=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mV2k5DuqD8P",
        "colab_type": "text"
      },
      "source": [
        "# Línea base\n",
        "\n",
        "Recordemos que es una buena práctica tener un primer valor de estimación como línea base, donde trabajemos con los **datos en bruto** y así podamos comprobar la validez de las transformaciones y filtrados del preprocesamiento. \n",
        "\n",
        "En esta ocasión vamos a intentar predecir si una persona tiene diabetes con un conjunto conocido que es el de los [indios PIMA](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G53-nLnqOMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "DATA_PATH=\"\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJd9pjTmqOa_",
        "colab_type": "text"
      },
      "source": [
        "Cargamos datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHwca7AArG2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c2e9b334-43c5-48d5-efcb-70f340537f5b"
      },
      "source": [
        "df = pd.read_csv(DATA_PATH + 'pima-indians-diabetes.csv')\n",
        "df.columns"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['pregnant_times', 'glucose', 'blood_pressure', 'tst', 'insulin', 'bmi',\n",
              "       'dpf', 'age', 'is_diabetic'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNm55yWNrL6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Seleccionamos columnas de características\n",
        "feature_cols = ['pregnant_times', 'glucose', 'blood_pressure', 'tst', 'insulin', 'bmi', 'dpf', 'age']\n",
        "X = df[feature_cols]\n",
        "\n",
        "# seleccionamos columna objetivo\n",
        "y = df['is_diabetic']"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "657NGeiwraaz",
        "colab_type": "text"
      },
      "source": [
        "Vamos a entrenar con un algoritmo KNN. Evaluaremos con validación cruzada debido a la escasez de datos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txf98VkWrWOn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "61c6f804-ed05-4504-ac31-289e5ec899a4"
      },
      "source": [
        "# Usaremos validación cruzada para evaluar\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Dejamos 20% para validación final\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2) \n",
        "print('train: %d, test %d' % (X_train.shape[0], X_test.shape[0]))\n",
        "\n",
        "# Evaluamos el modelo\n",
        "scoring = ('accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1')\n",
        "clf = KNeighborsClassifier()\n",
        "scores = cross_validate(clf, X_train, y_train, cv=10, scoring=scoring) # por defecto, es estratificado\n",
        "for m in scoring:\n",
        "  print(m, \"%0.2f (+/- %0.2f)\" % (scores['test_'+m].mean(), scores['test_'+m].std() * 2))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: 614, test 154\n",
            "accuracy 0.73 (+/- 0.13)\n",
            "balanced_accuracy 0.69 (+/- 0.13)\n",
            "precision 0.65 (+/- 0.22)\n",
            "recall 0.56 (+/- 0.25)\n",
            "f1 0.59 (+/- 0.17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRuae-ODsRHI",
        "colab_type": "text"
      },
      "source": [
        "**Pregunta**\n",
        "\n",
        "¿Cómo varían los resultados al modificar el tamaño de las particiones (parámetro `cv` )?\n",
        "\n",
        "Razona tu respuesta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7ovyjC3srj1",
        "colab_type": "text"
      },
      "source": [
        "### Probando varios clasificadores\n",
        "\n",
        "Vamos a construir un evaluador con los siguientes algoritmos de clasificación facilitados por Scikit-learn:\n",
        "\n",
        "* [Regresión logística](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)\n",
        "* [Support Vector Classification (SVC)](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)\n",
        "* [Stochastic Gradient Descent](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier)\n",
        "* [Árbol de decisión](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier)\n",
        "* [Random forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier)\n",
        "* [KNN](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
        "* [Multi-Layer Perceptron](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfOaFalAsvRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def eval_classifiers(X_train, y_train):\n",
        "  clfs = [('Logistic regression', LogisticRegression(max_iter=1000)),\n",
        "          ('SVM', SVC()),\n",
        "          ('Decision tree', DecisionTreeClassifier()),\n",
        "          ('RandomForest', RandomForestClassifier(n_estimators=20, random_state=45)),\n",
        "          ('SGD', SGDClassifier(max_iter=1000, tol=1e-4, random_state=45)),\n",
        "          ('KNN', KNeighborsClassifier()),\n",
        "          ('MLP', MLPClassifier(max_iter=1000))\n",
        "          ]\n",
        "\n",
        "  # Vamos devolver los resultados como una tabla\n",
        "  # Cada fila un algoritmo, cada columna un resultado\n",
        "  results = pd.DataFrame(columns=['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f-score'])\n",
        "  for alg, clf in clfs:\n",
        "    scores = cross_validate(clf, X_train, y_train, cv=10, scoring=scoring) # por defecto, es estratificado\n",
        "    results.loc[alg,:] = [scores['test_'+m].mean() for m in scoring]\n",
        "  return results.sort_values(by='f-score', ascending=False)\n",
        "  "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZRHLenNsyzr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "91d5d6b5-f57c-48be-97e5-1abc9c29fd37"
      },
      "source": [
        "# 4 decimales para cada valor en Pandas\n",
        "pd.options.display.float_format = '{:,.4f}'.format\n",
        "  \n",
        "eval_classifiers(X_train, y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>balanced_accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic regression</th>\n",
              "      <td>0.7735</td>\n",
              "      <td>0.7307</td>\n",
              "      <td>0.7327</td>\n",
              "      <td>0.5827</td>\n",
              "      <td>0.6412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForest</th>\n",
              "      <td>0.7540</td>\n",
              "      <td>0.7137</td>\n",
              "      <td>0.6962</td>\n",
              "      <td>0.5738</td>\n",
              "      <td>0.6234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.7669</td>\n",
              "      <td>0.7144</td>\n",
              "      <td>0.7426</td>\n",
              "      <td>0.5325</td>\n",
              "      <td>0.6134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.7263</td>\n",
              "      <td>0.6904</td>\n",
              "      <td>0.6465</td>\n",
              "      <td>0.5649</td>\n",
              "      <td>0.5919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision tree</th>\n",
              "      <td>0.6725</td>\n",
              "      <td>0.6438</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.5455</td>\n",
              "      <td>0.5402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.6970</td>\n",
              "      <td>0.6527</td>\n",
              "      <td>0.5858</td>\n",
              "      <td>0.4998</td>\n",
              "      <td>0.5379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD</th>\n",
              "      <td>0.6529</td>\n",
              "      <td>0.5660</td>\n",
              "      <td>0.4359</td>\n",
              "      <td>0.2686</td>\n",
              "      <td>0.2994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy balanced_accuracy precision recall f-score\n",
              "Logistic regression   0.7735            0.7307    0.7327 0.5827  0.6412\n",
              "RandomForest          0.7540            0.7137    0.6962 0.5738  0.6234\n",
              "SVM                   0.7669            0.7144    0.7426 0.5325  0.6134\n",
              "KNN                   0.7263            0.6904    0.6465 0.5649  0.5919\n",
              "Decision tree         0.6725            0.6438    0.5375 0.5455  0.5402\n",
              "MLP                   0.6970            0.6527    0.5858 0.4998  0.5379\n",
              "SGD                   0.6529            0.5660    0.4359 0.2686  0.2994"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6CFPKGItqrb",
        "colab_type": "text"
      },
      "source": [
        "# Preprocesamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD7huW0ttsm-",
        "colab_type": "text"
      },
      "source": [
        "## Escalado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43qoxXSttcTD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "outputId": "7414daae-6036-49a3-a369-eeaadb6997eb"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "scaler = preprocessing.StandardScaler()\n",
        "eval_classifiers(scaler.fit_transform(X_train), y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>balanced_accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic regression</th>\n",
              "      <td>0.7736</td>\n",
              "      <td>0.7307</td>\n",
              "      <td>0.7338</td>\n",
              "      <td>0.5827</td>\n",
              "      <td>0.6422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForest</th>\n",
              "      <td>0.7557</td>\n",
              "      <td>0.7160</td>\n",
              "      <td>0.6950</td>\n",
              "      <td>0.5784</td>\n",
              "      <td>0.6266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.7555</td>\n",
              "      <td>0.7108</td>\n",
              "      <td>0.7058</td>\n",
              "      <td>0.5554</td>\n",
              "      <td>0.6110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.7215</td>\n",
              "      <td>0.6906</td>\n",
              "      <td>0.6279</td>\n",
              "      <td>0.5829</td>\n",
              "      <td>0.5978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.7346</td>\n",
              "      <td>0.6962</td>\n",
              "      <td>0.6609</td>\n",
              "      <td>0.5641</td>\n",
              "      <td>0.5976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD</th>\n",
              "      <td>0.7230</td>\n",
              "      <td>0.6864</td>\n",
              "      <td>0.6412</td>\n",
              "      <td>0.5597</td>\n",
              "      <td>0.5808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision tree</th>\n",
              "      <td>0.6840</td>\n",
              "      <td>0.6571</td>\n",
              "      <td>0.5529</td>\n",
              "      <td>0.5643</td>\n",
              "      <td>0.5563</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy balanced_accuracy precision recall f-score\n",
              "Logistic regression   0.7736            0.7307    0.7338 0.5827  0.6422\n",
              "RandomForest          0.7557            0.7160    0.6950 0.5784  0.6266\n",
              "SVM                   0.7555            0.7108    0.7058 0.5554  0.6110\n",
              "MLP                   0.7215            0.6906    0.6279 0.5829  0.5978\n",
              "KNN                   0.7346            0.6962    0.6609 0.5641  0.5976\n",
              "SGD                   0.7230            0.6864    0.6412 0.5597  0.5808\n",
              "Decision tree         0.6840            0.6571    0.5529 0.5643  0.5563"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67Qf8jjD0ZIZ",
        "colab_type": "text"
      },
      "source": [
        "## Interacciones"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CjWbfejt6CT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e72989ab-8b80-4002-b86c-1e0a8e602c97"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
        "eval_classifiers(poly.fit_transform(X_train), y_train)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>balanced_accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Logistic regression</th>\n",
              "      <td>0.7556</td>\n",
              "      <td>0.7077</td>\n",
              "      <td>0.7074</td>\n",
              "      <td>0.5418</td>\n",
              "      <td>0.6090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RandomForest</th>\n",
              "      <td>0.7312</td>\n",
              "      <td>0.6942</td>\n",
              "      <td>0.6481</td>\n",
              "      <td>0.5652</td>\n",
              "      <td>0.5987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.7198</td>\n",
              "      <td>0.6937</td>\n",
              "      <td>0.6114</td>\n",
              "      <td>0.6017</td>\n",
              "      <td>0.5979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.7506</td>\n",
              "      <td>0.6864</td>\n",
              "      <td>0.7400</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.5592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision tree</th>\n",
              "      <td>0.6726</td>\n",
              "      <td>0.6453</td>\n",
              "      <td>0.5407</td>\n",
              "      <td>0.5502</td>\n",
              "      <td>0.5402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLP</th>\n",
              "      <td>0.6873</td>\n",
              "      <td>0.6468</td>\n",
              "      <td>0.5812</td>\n",
              "      <td>0.5082</td>\n",
              "      <td>0.5189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SGD</th>\n",
              "      <td>0.5684</td>\n",
              "      <td>0.5458</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.4643</td>\n",
              "      <td>0.3760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy balanced_accuracy precision recall f-score\n",
              "Logistic regression   0.7556            0.7077    0.7074 0.5418  0.6090\n",
              "RandomForest          0.7312            0.6942    0.6481 0.5652  0.5987\n",
              "KNN                   0.7198            0.6937    0.6114 0.6017  0.5979\n",
              "SVM                   0.7506            0.6864    0.7400 0.4636  0.5592\n",
              "Decision tree         0.6726            0.6453    0.5407 0.5502  0.5402\n",
              "MLP                   0.6873            0.6468    0.5812 0.5082  0.5189\n",
              "SGD                   0.5684            0.5458    0.3957 0.4643  0.3760"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rgbOwRduix6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_classifiers(scaler.fit_transform(poly.fit_transform(X_train)), y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDb1qPoVvuGK",
        "colab_type": "text"
      },
      "source": [
        "# Búsqueda de hiperparámetros\n",
        "\n",
        "Scikit-learn ofrece herramientas para ayudarnos en la búsqueda de los parámetros para el algoritmo de entrenamiento. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwZ_9Sa9u1B0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "910b9e9b-633b-4903-e135-edb88a0de67c"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Establecemos posibles parámetros a explorar (6 experimentos en total)\n",
        "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10]},\n",
        "                    {'kernel': ['linear'], 'C': [1, 10]}]\n",
        "\n",
        "clf = GridSearchCV(SVC(), tuned_parameters, scoring='f1_macro')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Mejores hiperparámetros:\")\n",
        "print(clf.best_params_)\n",
        "print(\"Resultados para distintas combinaciones:\")\n",
        "means = clf.cv_results_['mean_test_score']\n",
        "stds = clf.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejores hiperparámetros:\n",
            "{'C': 1, 'kernel': 'linear'}\n",
            "Resultados para distintas combinaciones:\n",
            "0.703 (+/-0.101) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.716 (+/-0.105) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.671 (+/-0.066) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
            "0.712 (+/-0.098) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
            "0.738 (+/-0.055) for {'C': 1, 'kernel': 'linear'}\n",
            "0.738 (+/-0.051) for {'C': 10, 'kernel': 'linear'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXsQd8SEwcf_",
        "colab_type": "text"
      },
      "source": [
        "# Ejercicios\n",
        "\n",
        "1. Resuelve la clasificación de los datos de la flor de Iris aplicando los siguiente:\n",
        "\n",
        "* Algortimo [PCA](https://scikit-learn.org/stable/modules/decomposition.html#principal-component-analysis-pca) para reducir la dimensionalidad a dos características. \n",
        "\n",
        "* Algoritmo de [Regresión Logística](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) para entrenar el modelo.\n",
        "\n",
        "* [Validación cruzada](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) sobre el conjunto total de datos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcUNggX6pWxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm,datasets\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Cargamos datos\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uye0fs1gqZ51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "173e4ac0-de0f-4e80-a342-ca661f20b1b8"
      },
      "source": [
        "# Reducimos dimensionalidad (usa random_state=42 para reproducir resultados)\n",
        "pca=PCA(n_components=2, random_state= 42) \n",
        "pca.fit(X) \n",
        "\n",
        "Xr = pca.transform(X) \n",
        "Xr.shape"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EpCYOdzqsWr",
        "colab_type": "text"
      },
      "source": [
        "Resultado esperado:\n",
        "\n",
        "```\n",
        "(150, 2)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATS_tSGuqxEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "72c2a607-750c-44c9-e383-724167c0547a"
      },
      "source": [
        "# Creamos clasificador (usa random_state=42 para reproducir resultados)\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.get_params()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1.0,\n",
              " 'class_weight': None,\n",
              " 'dual': False,\n",
              " 'fit_intercept': True,\n",
              " 'intercept_scaling': 1,\n",
              " 'l1_ratio': None,\n",
              " 'max_iter': 100,\n",
              " 'multi_class': 'auto',\n",
              " 'n_jobs': None,\n",
              " 'penalty': 'l2',\n",
              " 'random_state': 42,\n",
              " 'solver': 'lbfgs',\n",
              " 'tol': 0.0001,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtdA3zmArK4_",
        "colab_type": "text"
      },
      "source": [
        "Resultado esperado:\n",
        "```\n",
        "{'C': 1.0,\n",
        " 'class_weight': None,\n",
        " 'dual': False,\n",
        " 'fit_intercept': True,\n",
        " 'intercept_scaling': 1,\n",
        " 'l1_ratio': None,\n",
        " 'max_iter': 100,\n",
        " 'multi_class': 'auto',\n",
        " 'n_jobs': None,\n",
        " 'penalty': 'l2',\n",
        " 'random_state': 42,\n",
        " 'solver': 'lbfgs',\n",
        " 'tol': 0.0001,\n",
        " 'verbose': 0,\n",
        " 'warm_start': False}\n",
        " ```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi-LQVySrOVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "f33f2d75-7905-4ebd-b796-c55f48a8f59e"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore') # filtramos warnings\n",
        "\n",
        "# Lanzamos validación cruzada de 10 particiones y mostramos resultados\n",
        "scoring = ['precision_macro', 'recall_macro', 'f1_macro']\n",
        "skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True) # particionado de xval, para reproducir resultados\n",
        "\n",
        "scores = cross_validate(clf, X, y,  scoring=scoring, cv = skf)\n",
        "for m in scoring:\n",
        "  print(m, \"%.4f\" % (scores['test_'+m].mean()))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision_macro 0.9771\n",
            "recall_macro 0.9733\n",
            "f1_macro 0.9728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px_y5pGP0-TX",
        "colab_type": "text"
      },
      "source": [
        "Resultado esperado:\n",
        "```\n",
        "precision_macro 0.9683\n",
        "recall_macro 0.9600\n",
        "f1_macro 0.9592\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_N-d-But742",
        "colab_type": "text"
      },
      "source": [
        "2. Repite el proceso anterior, pero con una búsqueda de hiperparámetros para la regresión logística.\n",
        "\n",
        "Valores a experimentar con los hiperparámetros siguientes:\n",
        "\n",
        "``` \n",
        "[{'solver': ['newton-cg', 'lbfgs', 'sag'], \n",
        "  'penalty': ['l2'],\n",
        "  'tol': [1e-3, 1e-4, 1e-5],\n",
        "  'C': [1, 10, 50],\n",
        "  'max_iter': [1000]},\n",
        " {'solver': ['saga'],\n",
        "  'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "  'tol': [1e-3, 1e-4, 1e-5],\n",
        "  'C': [1, 10, 50],\n",
        "  'max_iter': [1000]},\n",
        " {'solver': ['liblinear'],\n",
        "  'penalty': ['l1'],\n",
        "  'tol': [1e-3, 1e-4, 1e-5],\n",
        "  'C': [1, 10, 50],\n",
        "  'max_iter': [1000]}\n",
        "  ]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX8ATKGfurUe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55103ca0-3d03-4969-e026-464218ee82b1"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore') # filtramos warnings\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Establecemos posibles parámetros a explorar (6 experimentos en total)\n",
        "tuned_parameters = [{'solver': ['newton-cg', 'lbfgs', 'sag'], \n",
        "  'penalty': ['l2'],\n",
        "  'tol': [1e-3, 1e-4, 1e-5],\n",
        "  'C': [1, 10, 50],\n",
        "  'max_iter': [1000]},\n",
        " {'solver': ['saga'],\n",
        "  'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "  'tol': [1e-3, 1e-4, 1e-5],\n",
        "  'C': [1, 10, 50],\n",
        "  'max_iter': [1000]},\n",
        " {'solver': ['liblinear'],\n",
        "  'penalty': ['l1'],\n",
        "  'tol': [1e-3, 1e-4, 1e-5],\n",
        "  'C': [1, 10, 50],\n",
        "  'max_iter': [1000]}\n",
        "  ]\n",
        "\n",
        "# usaremos 'f1_macro' como métrica objetivo en la búsqueda grid\n",
        "estimate = LogisticRegression(random_state=42)\n",
        "\n",
        "clf = GridSearchCV(estimator = estimate, param_grid=tuned_parameters, scoring='f1_macro')\n",
        "clf.fit(X, y)\n",
        "\n",
        "print(\"Mejores hiperparámetros:\")\n",
        "print(clf.best_params_)\n",
        "print(\"Resultados para distintas combinaciones:\")\n",
        "means = clf.cv_results_['mean_test_score']\n",
        "stds = clf.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "    print(\"%0.6f (+/-%0.6f) for %r\" % (mean, std * 2, params))\n",
        "\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mejores hiperparámetros:\n",
            "{'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
            "Resultados para distintas combinaciones:\n",
            "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001}\n",
            "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001}\n",
            "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05}\n",
            "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001}\n",
            "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001}\n",
            "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05}\n",
            "0.979983 (+/-0.053350) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001}\n",
            "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001}\n",
            "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05}\n",
            "0.973300 (+/-0.049907) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001}\n",
            "0.973300 (+/-0.049907) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001}\n",
            "0.973300 (+/-0.049907) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05}\n",
            "0.973300 (+/-0.049907) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001}\n",
            "0.973300 (+/-0.049907) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001}\n",
            "0.973300 (+/-0.049907) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05}\n",
            "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001}\n",
            "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001}\n",
            "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05}\n",
            "0.986633 (+/-0.032742) for {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
            "0.979983 (+/-0.053350) for {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
            "0.979983 (+/-0.053350) for {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
            "0.986633 (+/-0.032742) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
            "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
            "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
            "nan (+/-nan) for {'C': 1, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001}\n",
            "nan (+/-nan) for {'C': 1, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001}\n",
            "nan (+/-nan) for {'C': 1, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05}\n",
            "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
            "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
            "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
            "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
            "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
            "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
            "nan (+/-nan) for {'C': 10, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001}\n",
            "nan (+/-nan) for {'C': 10, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001}\n",
            "nan (+/-nan) for {'C': 10, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
            "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
            "nan (+/-nan) for {'C': 50, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001}\n",
            "nan (+/-nan) for {'C': 50, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001}\n",
            "nan (+/-nan) for {'C': 50, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05}\n",
            "0.959933 (+/-0.077895) for {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
            "0.959933 (+/-0.077895) for {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
            "0.959933 (+/-0.077895) for {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
            "0.973199 (+/-0.065651) for {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
            "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
            "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
            "0.966515 (+/-0.059931) for {'C': 50, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
            "0.966515 (+/-0.059931) for {'C': 50, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
            "0.966515 (+/-0.059931) for {'C': 50, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrE9szZMzaY0",
        "colab_type": "text"
      },
      "source": [
        "Resultado esperado:\n",
        "\n",
        "```\n",
        "Mejores hiperparámetros:\n",
        "{'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
        "Resultados para distintas combinaciones:\n",
        "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001}\n",
        "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001}\n",
        "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05}\n",
        "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001}\n",
        "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001}\n",
        "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05}\n",
        "0.979983 (+/-0.053350) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001}\n",
        "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001}\n",
        "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05}\n",
        "0.973300 (+/-0.049907) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001}\n",
        "0.973300 (+/-0.049907) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001}\n",
        "0.973300 (+/-0.049907) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05}\n",
        "0.973300 (+/-0.049907) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001}\n",
        "0.973300 (+/-0.049907) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001}\n",
        "0.973300 (+/-0.049907) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05}\n",
        "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001}\n",
        "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001}\n",
        "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05}\n",
        "0.986633 (+/-0.032742) for {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
        "0.979983 (+/-0.053350) for {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
        "0.979983 (+/-0.053350) for {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
        "0.986633 (+/-0.032742) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
        "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
        "0.973165 (+/-0.050339) for {'C': 1, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
        "nan (+/-nan) for {'C': 1, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001}\n",
        "nan (+/-nan) for {'C': 1, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001}\n",
        "nan (+/-nan) for {'C': 1, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05}\n",
        "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
        "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
        "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
        "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
        "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
        "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
        "nan (+/-nan) for {'C': 10, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001}\n",
        "nan (+/-nan) for {'C': 10, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001}\n",
        "nan (+/-nan) for {'C': 10, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001}\n",
        "0.979983 (+/-0.053350) for {'C': 50, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05}\n",
        "nan (+/-nan) for {'C': 50, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001}\n",
        "nan (+/-nan) for {'C': 50, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001}\n",
        "nan (+/-nan) for {'C': 50, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05}\n",
        "0.959933 (+/-0.077895) for {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
        "0.959933 (+/-0.077895) for {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
        "0.959933 (+/-0.077895) for {'C': 1, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
        "0.973199 (+/-0.065651) for {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
        "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
        "0.979983 (+/-0.053350) for {'C': 10, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
        "0.966515 (+/-0.059931) for {'C': 50, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
        "0.966515 (+/-0.059931) for {'C': 50, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
        "0.966515 (+/-0.059931) for {'C': 50, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liChL-xiowj7",
        "colab_type": "text"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "* [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtIYysXYo6vP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}